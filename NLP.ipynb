{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/Joven/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "[nltk_data] Downloading package punkt to /Users/Joven/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Bidirectional,LSTM,GRU,Dense\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "nltk.download('punkt')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# All zipped files must be unzipped and left within the submission folder to run the code.\n",
    "# Might give errors if ran in windows. Code processed and ran using MAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('train.txt','r')\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for i in f:\n",
    "    l=i.split(';')\n",
    "    y_train.append(l[1].strip())\n",
    "    x_train.append(l[0])\n",
    "f=open('test.txt','r')\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "for i in f:\n",
    "    l=i.split(';')\n",
    "    y_test.append(l[1].strip())\n",
    "    x_test.append(l[0])\n",
    "f=open('val.txt','r')\n",
    "for i in f:\n",
    "    l=i.split(';')\n",
    "    y_test.append(l[1].strip())\n",
    "    x_test.append(l[0])\n",
    "data_train=pd.DataFrame({'Text':x_train,'Emotion':y_train})\n",
    "data_test=pd.DataFrame({'Text':x_test,'Emotion':y_test})\n",
    "data=data_train.append(data_test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the prepositions, articles, punctuation marks, stop words, leaving only the important words in the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    data=re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data=re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "    data=word_tokenize(data)\n",
    "    return data\n",
    "texts=[' '.join(clean_text(text)) for text in data.Text]\n",
    "texts_train=[' '.join(clean_text(text)) for text in x_train]\n",
    "texts_test=[' '.join(clean_text(text)) for text in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It tokenizes each sentence, extracts each unique word and creates a dictionary where each unique word is assigned an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequence_train=tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test=tokenizer.texts_to_sequences(texts_test)\n",
    "index_of_words=tokenizer.word_index\n",
    "vocab_size=len(index_of_words)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data-set which we obtained has six unique results or emotions, namely: anger, sadness, fear, joy, surprise and love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=6\n",
    "embed_num_dims=300\n",
    "max_seq_len=500\n",
    "class_names=['anger','sadness','fear','joy','surprise','love']\n",
    "X_train_pad=pad_sequences(sequence_train,maxlen=max_seq_len)\n",
    "X_test_pad=pad_sequences(sequence_test,maxlen=max_seq_len)\n",
    "encoding={'anger':0,'sadness':1,'fear':2,'joy':3,'surprise':4,'love':5}\n",
    "y_train=[encoding[x] for x in data_train.Emotion]\n",
    "y_test=[encoding[x] for x in data_test.Emotion]\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath,word_index,embedding_dim):\n",
    "    vocab_size=len(word_index)+1\n",
    "    embedding_matrix=np.zeros((vocab_size,embedding_dim))\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word,*vector=line.split()\n",
    "            if word in word_index:\n",
    "                idx=word_index[word]\n",
    "                embedding_matrix[idx] = np.array(vector,dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix\n",
    "fname='wiki-news-300d-1M.vec'\n",
    "embedd_matrix=create_embedding_matrix(fname,index_of_words,embed_num_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer ----------> Bi-directional layer -----------> Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_layer=Embedding(vocab_size,embed_num_dims,input_length=max_seq_len,weights=[embedd_matrix],trainable=False)\n",
    "gru_output_size=128\n",
    "bidirectional=True\n",
    "model=Sequential()\n",
    "model.add(embedd_layer)\n",
    "model.add(Bidirectional(GRU(units=gru_output_size,dropout=0.2,recurrent_dropout=0.2)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 300)          5128500   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              330240    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,460,282\n",
      "Trainable params: 331,782\n",
      "Non-trainable params: 5,128,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "125/125 [==============================] - 492s 4s/step - loss: 1.3955 - accuracy: 0.4773 - val_loss: 1.1177 - val_accuracy: 0.5943\n",
      "Epoch 2/8\n",
      "125/125 [==============================] - 14079s 114s/step - loss: 0.9115 - accuracy: 0.6873 - val_loss: 0.6476 - val_accuracy: 0.7790\n",
      "Epoch 3/8\n",
      "125/125 [==============================] - 13451s 108s/step - loss: 0.5299 - accuracy: 0.8133 - val_loss: 0.3742 - val_accuracy: 0.8720\n",
      "Epoch 4/8\n",
      "125/125 [==============================] - 506s 4s/step - loss: 0.3389 - accuracy: 0.8801 - val_loss: 0.2576 - val_accuracy: 0.9100\n",
      "Epoch 5/8\n",
      "125/125 [==============================] - 674s 5s/step - loss: 0.2617 - accuracy: 0.9064 - val_loss: 0.2104 - val_accuracy: 0.9165\n",
      "Epoch 6/8\n",
      "125/125 [==============================] - 2190s 18s/step - loss: 0.2134 - accuracy: 0.9183 - val_loss: 0.1843 - val_accuracy: 0.9260\n",
      "Epoch 7/8\n",
      "125/125 [==============================] - 566s 5s/step - loss: 0.1942 - accuracy: 0.9209 - val_loss: 0.1715 - val_accuracy: 0.9265\n",
      "Epoch 8/8\n",
      "125/125 [==============================] - 495s 4s/step - loss: 0.1849 - accuracy: 0.9269 - val_loss: 0.1536 - val_accuracy: 0.9302\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=8\n",
    "hist=model.fit(X_train_pad,y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Map the categorical value back to it’s actual English emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue():\n",
    "    a = [input('Describe how your day is going:')]     # Question 1\n",
    "    seq=tokenizer.texts_to_sequences(a)\n",
    "    padded=pad_sequences(seq,maxlen=max_seq_len)\n",
    "    pred=model.predict(padded)\n",
    "    print('Message:'+str(a))\n",
    "    print('Emotion:',class_names[np.argmax(pred)])\n",
    "    b = [input('What are the thoughts that are going through your mind?')]     # Question 2\n",
    "    seq=tokenizer.texts_to_sequences(b)\n",
    "    padded=pad_sequences(seq,maxlen=max_seq_len)\n",
    "    pred=model.predict(padded)\n",
    "    print('Message:'+str(b))\n",
    "    print('Emotion:',class_names[np.argmax(pred)])\n",
    "    c = [input('Describe your emotions using only action words:')]       # Question 3\n",
    "    seq=tokenizer.texts_to_sequences(c)\n",
    "    padded=pad_sequences(seq,maxlen=max_seq_len)\n",
    "    pred=model.predict(padded)\n",
    "    print('Message:'+str(c))\n",
    "    print('Emotion:',class_names[np.argmax(pred)])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe how your day is going: My mum fell sick with covid and I am very worried\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message:['My mum fell sick with covid and I am very worried']\n",
      "Emotion: fear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the thoughts that are going through your mind? I am feeling miserable as I can't physically see my mum due to the isolation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message:[\"I am feeling miserable as I can't physically see my mum due to the isolation\"]\n",
      "Emotion: sadness\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe your emotions using only action words: hyperventilating and shaking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message:['hyperventilating and shaking']\n",
      "Emotion: fear\n"
     ]
    }
   ],
   "source": [
    "dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
